{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniela2001v2-png/medflow/blob/main/medflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZBPhGxtSKgG"
      },
      "source": [
        "# MedFlow MVP - Google Colab\n",
        "\n",
        "* Hecho por: Yeinmy Daniela Morales Barrera - ymoral35@estudiante.ibero.edu.co\n",
        "* Fecha: 30 de Octubre de 2025\n",
        "\n",
        "\n",
        "INSTRUCCIONES:\n",
        "1. Runtime > Cambie el tipo de tiempo de ejecuci√≥n (Runtime) > T4 GPU\n",
        "2. Ejecuta CELDA 1, luego CELDA 2, etc. en orden\n",
        "3. La √∫ltima celda lanzar√° la interfaz del usuario\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ9yMnb4V-nb",
        "outputId": "b4a6496d-d0bd-4817-f770-b87db875796c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Instalando dependencias...\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.12/dist-packages (8.1.3)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.12/dist-packages (3.0.2)\n",
            "Requirement already satisfied: nbsphinx in /usr/local/lib/python3.12/dist-packages (0.9.7)\n",
            "Requirement already satisfied: sphinx-autodoc-typehints in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.12/dist-packages (from sphinx) (3.1.6)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.12/dist-packages (from sphinx) (2.19.2)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.12/dist-packages (from sphinx) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.12/dist-packages (from sphinx) (2.32.4)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from sphinx) (25.0)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.12/dist-packages (from sphinx-rtd-theme) (4.1)\n",
            "Requirement already satisfied: nbconvert!=5.4,>=5.3 in /usr/local/lib/python3.12/dist-packages (from nbsphinx) (7.16.6)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.12/dist-packages (from nbsphinx) (5.7.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from nbsphinx) (5.10.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1->sphinx) (3.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert!=5.4,>=5.3->nbsphinx) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx) (5.9.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbsphinx) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbsphinx) (4.25.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx) (2025.11.12)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert!=5.4,>=5.3->nbsphinx) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert!=5.4,>=5.3->nbsphinx) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbsphinx) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbsphinx) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbsphinx) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbsphinx) (0.29.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.7->nbconvert!=5.4,>=5.3->nbsphinx) (4.5.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from nbclient>=0.5.0->nbconvert!=5.4,>=5.3->nbsphinx) (7.4.9)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert!=5.4,>=5.3->nbsphinx) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert!=5.4,>=5.3->nbsphinx) (4.15.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert!=5.4,>=5.3->nbsphinx) (0.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert!=5.4,>=5.3->nbsphinx) (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert!=5.4,>=5.3->nbsphinx) (2.9.0.post0)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert!=5.4,>=5.3->nbsphinx) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert!=5.4,>=5.3->nbsphinx) (6.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert!=5.4,>=5.3->nbsphinx) (1.17.0)\n",
            "‚úÖ Listo!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Instala las dependencias necesarias para el proyecto MedFlow.\n",
        "\n",
        "Las dependencias incluyen:\n",
        "- transformers: Para trabajar con modelos de Hugging Face.\n",
        "- accelerate: Para optimizar la inferencia del modelo en GPU.\n",
        "- gradio: Para crear la interfaz de usuario.\n",
        "- pillow: Para manejo de im√°genes.\n",
        "- requests: Para realizar peticiones HTTP.\n",
        "- torch: Para operaciones con tensores y uso de GPU.\n",
        "- sphinx, sphinx-rtd-theme, nbsphinx, sphinx-autodoc-typehints: Para la generaci√≥n de documentaci√≥n.\n",
        "\"\"\"\n",
        "print(\"üì¶ Instalando dependencias...\")\n",
        "\n",
        "# Instalar las dependencias principales en modo silencioso (-q)\n",
        "!pip install -q transformers==4.50.0 accelerate gradio pillow requests torch\n",
        "# Instalar dependencias para la generaci√≥n de documentaci√≥n\n",
        "!pip install sphinx sphinx-rtd-theme nbsphinx sphinx-autodoc-typehints\n",
        "print(\"‚úÖ Listo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uzeigiQWwbb"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Importa las librer√≠as y m√≥dulos necesarios para la aplicaci√≥n MedFlow.\n",
        "\n",
        "Se importan:\n",
        "- torch: Para operaciones con tensores y manejo de GPU.\n",
        "- AutoProcessor, AutoModelForImageTextToText de transformers: Para cargar el modelo y procesador de Hugging Face.\n",
        "- Image de PIL (Pillow): Para el manejo de im√°genes.\n",
        "- gradio: Para la construcci√≥n de la interfaz de usuario.\n",
        "- time: Para medir el tiempo de procesamiento.\n",
        "- traceback: Para obtener informaci√≥n detallada de errores.\n",
        "\"\"\"\n",
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import time\n",
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmQNcCy0W-dx"
      },
      "outputs": [],
      "source": [
        "def validate_gpu_type() -> bool:\n",
        "  \"\"\"\n",
        "  Valida el tipo de GPU a usar dentro del entorno de Google Colab.\n",
        "\n",
        "  Verifica si CUDA est√° disponible y, si es as√≠, imprime informaci√≥n sobre la GPU.\n",
        "  Limpia la cach√© de CUDA para liberar memoria.\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    bool: True si CUDA est√° disponible, False en caso contrario.\n",
        "  \"\"\"\n",
        "  print(\"\\nüîç Verificando GPU...\")\n",
        "  print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
        "  if torch.cuda.is_available():\n",
        "      print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "      print(f\"Memoria: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "      # Limpiar cache CUDA\n",
        "      torch.cuda.empty_cache()\n",
        "      return torch.cuda.is_available()\n",
        "  else:\n",
        "      print(\"‚ö†Ô∏è No hay GPU. Ve a Runtime > Change runtime type > T4 GPU\")\n",
        "      return False\n",
        "\n",
        "\n",
        "validate_gpu_type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjiTM4tHsG_R"
      },
      "outputs": [],
      "source": [
        "# Validar si se ha configurado CUDA (GPU)\n",
        "is_cuda_setted = validate_gpu_type()\n",
        "# Definir el ID del modelo a utilizar de Hugging Face\n",
        "MODEL_ID = \"google/medgemma-4b-it\"\n",
        "# Configurar el dispositivo de procesamiento ('cuda' si hay GPU, 'cpu' en caso contrario)\n",
        "device = \"cuda\" if is_cuda_setted else \"cpu\"\n",
        "\n",
        "\n",
        "def init_medflow_model():\n",
        "  \"\"\"\n",
        "  Inicializa el modelo de MedFlow (Med-GEMMA 4B Multimodal).\n",
        "\n",
        "  Descarga y carga el modelo y el procesador asociados desde Hugging Face.\n",
        "  Configura el modelo para usar bfloat16 y device_map=\"auto\" para optimizar el uso de memoria y recursos.\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    tuple: Una tupla conteniendo el procesador y el modelo cargados.\n",
        "           Retorna (None, None) si ocurre un error durante la carga.\n",
        "  \"\"\"\n",
        "\n",
        "  print(f\"\\nüè• Iniciando MedFlow...\")\n",
        "  print(f\"‚öôÔ∏è Dispositivo: {device}\")\n",
        "  print(f\"üì• Descargando modelo (5-10 min primera vez)...\\n\")\n",
        "\n",
        "  try:\n",
        "      # Cargar el procesador asociado al modelo\n",
        "      processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
        "\n",
        "      # Cargar el modelo pre-entrenado\n",
        "      model = AutoModelForImageTextToText.from_pretrained(\n",
        "          MODEL_ID,\n",
        "          torch_dtype=torch.bfloat16,  # Usar bfloat16 para eficiencia y compatibilidad con GPU\n",
        "          device_map=\"auto\",  # Distribuir el modelo autom√°ticamente entre dispositivos disponibles\n",
        "          low_cpu_mem_usage=True # Reducir el uso de CPU al cargar el modelo\n",
        "      )\n",
        "\n",
        "      print(\"‚úÖ Modelo cargado exitosamente!\\n\")\n",
        "      return processor, model\n",
        "\n",
        "  except Exception as e:\n",
        "      print(f\"‚ùå Error cargando modelo: {e}\")\n",
        "      traceback.print_exc()\n",
        "      return None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8SwPhRksJaY"
      },
      "outputs": [],
      "source": [
        "# Cargar el procesador y el modelo utilizando la funci√≥n init_medflow_model\n",
        "processor, model = init_medflow_model()\n",
        "\n",
        "# Verificar si el modelo y procesador se cargaron correctamente\n",
        "if processor is None or model is None:\n",
        "    print(\"üî¥ No se pudo cargar el modelo MedFlow. Verifique los mensajes de error anteriores.\")\n",
        "else:\n",
        "    print(\"üü¢ Modelo MedFlow listo para usar.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23ae6c0c"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Define la estructura y roles de los componentes de la interfaz de usuario (UI) de Gradio.\n",
        "\n",
        "Este diccionario `ui_components` mapea nombres l√≥gicos de componentes a sus\n",
        "tipos, roles (Input, Output, Action, Container, Display, Layout, etc.), y una\n",
        "breve descripci√≥n de su prop√≥sito.\n",
        "\n",
        "El diccionario `connected_function` describe la funci√≥n de backend que se\n",
        "ejecuta al interactuar con la UI, el evento que la dispara, y los componentes\n",
        "de entrada y salida involucrados.\n",
        "\n",
        "Returns:\n",
        "    None: Esta celda define variables globales y no retorna un valor.\n",
        "\"\"\"\n",
        "# Diccionario que identifica los componentes de la UI de Gradio, su tipo, rol y descripci√≥n.\n",
        "ui_components = {\n",
        "    \"imagen_input\": {\"type\": \"gr.Image\", \"role\": \"Input\", \"description\": \"Medical image input (X-ray, CT, etc.)\"},\n",
        "    \"tipo_analisis\": {\"type\": \"gr.Dropdown\", \"role\": \"Input\", \"description\": \"Type of analysis (General Description, Pathological Findings, Structured Report, Differential Diagnosis)\"},\n",
        "    \"idioma\": {\"type\": \"gr.Radio\", \"role\": \"Input\", \"description\": \"Report language (Spanish or English)\"},\n",
        "    \"procesar_btn\": {\"type\": \"gr.Button\", \"role\": \"Action\", \"description\": \"Button to trigger image analysis\"},\n",
        "    \"limpiar_btn\": {\"type\": \"gr.ClearButton\", \"role\": \"Action\", \"description\": \"Button to clear the image input\"},\n",
        "    \"reporte_output\": {\"type\": \"gr.Textbox\", \"role\": \"Output\", \"description\": \"Generated medical report\"},\n",
        "    \"status_output\": {\"type\": \"gr.Textbox\", \"role\": \"Output\", \"description\": \"Processing status\"},\n",
        "    \"metadata_output\": {\"type\": \"gr.Markdown\", \"role\": \"Output\", \"description\": \"Processing metadata\"},\n",
        "    \"demo\": {\"type\": \"gr.Blocks\", \"role\": \"Container\", \"description\": \"Main container for the Gradio application\"},\n",
        "    \"Markdown\": {\"type\": \"gr.Markdown\", \"role\": \"Display\", \"description\": \"Used for titles, descriptions, and instructions\"},\n",
        "    \"Row\": {\"type\": \"gr.Row\", \"role\": \"Layout\", \"description\": \"Arranges components horizontally\"},\n",
        "    \"Column\": {\"type\": \"gr.Column\", \"role\": \"Layout\", \"description\": \"Arranges components vertically\"},\n",
        "    \"Accordion\": {\"type\": \"gr.Accordion\", \"role\": \"Layout\", \"description\": \"Collapsible section for content\"},\n",
        "    \"Examples\": {\"type\": \"gr.Examples\", \"role\": \"Input/Demonstration\", \"description\": \"Provides example inputs\"},\n",
        "}\n",
        "\n",
        "# Diccionario que identifica la funci√≥n conectada a un evento de la UI y sus interacciones (entradas/salidas).\n",
        "connected_function = {\n",
        "    \"name\": \"analizar_imagen\",\n",
        "    \"triggered_by\": \"procesar_btn.click\",\n",
        "    \"inputs\": [\"imagen_input\", \"tipo_analisis\", \"idioma\"],\n",
        "    \"outputs\": [\"reporte_output\", \"metadata_output\", \"status_output\"]\n",
        "}\n",
        "\n",
        "# Imprimir la informaci√≥n de los componentes identificados y la funci√≥n conectada.\n",
        "print(\"Identified UI Components:\")\n",
        "for component, details in ui_components.items():\n",
        "    print(f\"- {component}: Type={details['type']}, Role={details['role']}, Description={details['description']}\")\n",
        "\n",
        "print(\"\\nConnected Function:\")\n",
        "print(f\"- Name: {connected_function['name']}\")\n",
        "print(f\"- Triggered by: {connected_function['triggered_by']}\")\n",
        "print(f\"- Inputs: {connected_function['inputs']}\")\n",
        "print(f\"- Outputs: {connected_function['outputs']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b337e986"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def create_input_section():\n",
        "    \"\"\"\n",
        "    Crea y configura la secci√≥n de entrada de la interfaz de usuario.\n",
        "\n",
        "    Esta secci√≥n incluye el componente de carga de imagen, el men√∫ desplegable\n",
        "    para el tipo de an√°lisis, los botones de radio para el idioma y los botones\n",
        "    de procesar y limpiar.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Una tupla conteniendo:\n",
        "            - gr.Column: El layout de columna de Gradio para la secci√≥n de entrada.\n",
        "            - gr.Image: El componente de entrada de imagen.\n",
        "            - gr.Dropdown: El men√∫ desplegable para el tipo de an√°lisis.\n",
        "            - gr.Radio: Los botones de radio para el idioma.\n",
        "            - gr.Button: El bot√≥n para iniciar el an√°lisis.\n",
        "            - gr.ClearButton: El bot√≥n para limpiar la entrada de imagen.\n",
        "    \"\"\"\n",
        "    with gr.Column(scale=1) as input_col:\n",
        "        gr.Markdown(\"### üì§ Entrada de Datos\")\n",
        "\n",
        "        imagen_input = gr.Image(\n",
        "            type=\"pil\",\n",
        "            label=\"üì∑ Imagen M√©dica (Rayos X, TC, etc.)\",\n",
        "            height=350\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"**Configuraci√≥n:**\")\n",
        "\n",
        "        tipo_analisis = gr.Dropdown(\n",
        "            choices=[\n",
        "                \"Descripci√≥n General\",\n",
        "                \"Hallazgos Patol√≥gicos\",\n",
        "                \"Reporte Estructurado\",\n",
        "                \"Diagn√≥stico Diferencial\"\n",
        "            ],\n",
        "            value=\"Reporte Estructurado\",\n",
        "            label=\"üîç Tipo de An√°lisis\",\n",
        "            info=\"Selecciona el enfoque del an√°lisis\"\n",
        "        )\n",
        "\n",
        "        idioma = gr.Radio(\n",
        "            choices=[\"Espa√±ol\", \"Ingl√©s\"],\n",
        "            value=\"Espa√±ol\",\n",
        "            label=\"üåê Idioma del Reporte\"\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            procesar_btn = gr.Button(\n",
        "                \"üöÄ Analizar Imagen\",\n",
        "                variant=\"primary\",\n",
        "                size=\"lg\",\n",
        "                scale=2\n",
        "            )\n",
        "            limpiar_btn = gr.ClearButton(\n",
        "                components=[imagen_input],\n",
        "                value=\"üóëÔ∏è Limpiar\",\n",
        "                size=\"lg\",\n",
        "                scale=1\n",
        "            )\n",
        "    return input_col, imagen_input, tipo_analisis, idioma, procesar_btn, limpiar_btn\n",
        "\n",
        "\n",
        "def create_output_section():\n",
        "    \"\"\"\n",
        "    Crea y configura la secci√≥n de salida de la interfaz de usuario.\n",
        "\n",
        "    Esta secci√≥n incluye el cuadro de texto para mostrar el reporte m√©dico\n",
        "    generado y el cuadro de texto para mostrar el estado del procesamiento.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Una tupla conteniendo:\n",
        "            - gr.Column: El layout de columna de Gradio para la secci√≥n de salida.\n",
        "            - gr.Textbox: El cuadro de texto para el reporte generado.\n",
        "            - gr.Textbox: El cuadro de texto para el procesamiento.\n",
        "    \"\"\"\n",
        "    with gr.Column(scale=1) as output_col:\n",
        "        gr.Markdown(\"### üìã Resultado del An√°lisis\")\n",
        "\n",
        "        reporte_output = gr.Markdown(\n",
        "            value=\"*El reporte aparecer√° aqu√≠ despu√©s de procesar la imagen...*\",\n",
        "            label=\"Reporte M√©dico Generado\",\n",
        "            # Markdown no tiene 'lines', pero puedes controlar altura con CSS\n",
        "        )\n",
        "\n",
        "        status_output = gr.Textbox(\n",
        "            label=\"Estado del Proceso\",\n",
        "            lines=1,\n",
        "            interactive=False,\n",
        "            show_copy_button=False\n",
        "        )\n",
        "\n",
        "    return output_col, reporte_output, status_output\n",
        "\n",
        "\n",
        "def create_metadata_accordion():\n",
        "    \"\"\"\n",
        "    Crea y configura el acorde√≥n de metadatos.\n",
        "\n",
        "    Esta secci√≥n de acorde√≥n se utiliza para mostrar metadatos de procesamiento\n",
        "    utilizando un componente Markdown.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Una tupla conteniendo:\n",
        "            - gr.Accordion: El componente acorde√≥n de Gradio.\n",
        "            - gr.Markdown: El componente Markdown para mostrar metadatos.\n",
        "    \"\"\"\n",
        "    with gr.Accordion(\"üìä Metadatos de Procesamiento\", open=False) as metadata_acc:\n",
        "        metadata_output = gr.Markdown()\n",
        "    return metadata_acc, metadata_output\n",
        "\n",
        "def create_guide_accordion():\n",
        "    \"\"\"\n",
        "    Crea y configura el acorde√≥n de la gu√≠a de uso.\n",
        "\n",
        "    Esta secci√≥n de acorde√≥n contiene instrucciones detalladas, tipos de im√°genes\n",
        "    soportadas, especificaciones t√©cnicas, limitaciones y fases futuras del\n",
        "    proyecto dentro de un componente Markdown.\n",
        "\n",
        "    Returns:\n",
        "        gr.Accordion: El componente acorde√≥n de Gradio que contiene la gu√≠a de uso.\n",
        "    \"\"\"\n",
        "    guide_markdown = \"\"\"\n",
        "        ### üéØ Instrucciones Detalladas:\n",
        "\n",
        "        1. **Preparar Imagen:**\n",
        "           - Formatos soportados: JPG, PNG, DICOM\n",
        "           - Tama√±o recomendado: < 5MB\n",
        "           - Resoluci√≥n √≥ptima: 512x512 a 2048x2048 p√≠xeles\n",
        "\n",
        "        2. **Cargar Imagen:**\n",
        "           - Haz clic en el √°rea de carga\n",
        "           - Selecciona archivo o arrastra la imagen\n",
        "           - Espera a que se visualice\n",
        "\n",
        "        3. **Configurar An√°lisis:**\n",
        "           - **Descripci√≥n General:** Identificaci√≥n de estructuras anat√≥micas\n",
        "           - **Hallazgos Patol√≥gicos:** Detecci√≥n espec√≠fica de anomal√≠as\n",
        "           - **Reporte Estructurado:** Formato radiol√≥gico est√°ndar (T√âCNICA/HALLAZGOS/IMPRESI√ìN)\n",
        "           - **Diagn√≥stico Diferencial:** Lista de posibles diagn√≥sticos\n",
        "\n",
        "        4. **Ejecutar:**\n",
        "           - Presiona \"Analizar Imagen\"\n",
        "           - Espera 10-30 segundos seg√∫n tama√±o de imagen\n",
        "           - Revisa el reporte generado\n",
        "\n",
        "        ### üìö Tipos de Im√°genes Soportadas:\n",
        "\n",
        "        | Modalidad | Ejemplos |\n",
        "        |-----------|----------|\n",
        "        | **Radiolog√≠a** | Rayos X t√≥rax, abdomen, extremidades |\n",
        "        | **Tomograf√≠a** | TC cerebral, tor√°cica, abdominal |\n",
        "        | **Dermatolog√≠a** | Lesiones cut√°neas, erupciones |\n",
        "        | **Patolog√≠a** | Histopatolog√≠a, biopsias |\n",
        "        | **Oftalmolog√≠a** | Fondo de ojo, retinograf√≠as |\n",
        "\n",
        "        ### ‚öôÔ∏è Especificaciones T√©cnicas:\n",
        "\n",
        "        - **Modelo Base:** Med-GEMMA 4B Multimodal\n",
        "        - **Arquitectura:** Gemma 3 + SigLIP Image Encoder\n",
        "        - **Entrenamiento:** Datos m√©dicos (MIMIC-CXR, PathMCQA, etc.)\n",
        "        - **Precisi√≥n Reportada:** 88.9 macro F1 en clasificaci√≥n MIMIC-CXR\n",
        "        - **Hardware:** Google Colab T4 GPU (16GB VRAM)\n",
        "        - **Framework:** PyTorch + Hugging Face Transformers\n",
        "\n",
        "        ### üî¨ Limitaciones del MVP:\n",
        "\n",
        "        - No reemplaza el juicio cl√≠nico profesional\n",
        "        - Optimizado para im√°genes en ingl√©s (dataset base)\n",
        "        - Sin fine-tuning para datos colombianos espec√≠ficos\n",
        "        - Sin integraci√≥n con sistemas hospitalarios PACS\n",
        "        - Sin validaci√≥n cl√≠nica por radi√≥logos certificados\n",
        "\n",
        "        ### üìà Pr√≥ximas Fases del Proyecto:\n",
        "\n",
        "        1. **Fase 2:** Fine-tuning con datos colombianos\n",
        "        2. **Fase 3:** Validaci√≥n con radi√≥logos locales\n",
        "        3. **Fase 4:** Integraci√≥n PACS/RIS\n",
        "        4. **Fase 5:** Cumplimiento normativo (Ley 1581 de 2012)\n",
        "        \"\"\"\n",
        "    with gr.Accordion(\"üìñ Gu√≠a de Uso Completa\", open=False) as guide_acc:\n",
        "        gr.Markdown(guide_markdown)\n",
        "    return guide_acc\n",
        "\n",
        "def create_examples_section(imagen_input, tipo_analisis, idioma):\n",
        "    \"\"\"\n",
        "    Crea y configura la secci√≥n de ejemplos.\n",
        "\n",
        "    Esta secci√≥n proporciona ejemplos de entrada en los que los usuarios pueden hacer\n",
        "    clic para poblar los campos de entrada y ver c√≥mo funciona la aplicaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        imagen_input (gr.Image): El componente de entrada de imagen para vincular ejemplos.\n",
        "        tipo_analisis (gr.Dropdown): El men√∫ desplegable del tipo de an√°lisis para vincular ejemplos.\n",
        "        idioma (gr.Radio): Los botones de radio del idioma para vincular ejemplos.\n",
        "\n",
        "    Returns:\n",
        "        gr.Examples: El componente Gradio Examples.\n",
        "    \"\"\"\n",
        "    # URL de la imagen de ejemplo\n",
        "    example_image_url = \"https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png\"\n",
        "    # Nombre del archivo local para la imagen de ejemplo\n",
        "    example_image_filename = \"chest_xray_example.png\"\n",
        "\n",
        "    # Descargar la imagen si no existe localmente\n",
        "    if not os.path.exists(example_image_filename):\n",
        "        try:\n",
        "            print(f\"Descargando imagen de ejemplo desde: {example_image_url}\")\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "            }\n",
        "            response = requests.get(example_image_url, headers=headers, stream=True, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            with open(example_image_filename, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            print(f\"Imagen de ejemplo descargada a: {example_image_filename}\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error al descargar la imagen de ejemplo: {e}\")\n",
        "            # Si falla la descarga, usar una lista de ejemplos vac√≠a\n",
        "            examples_data = []\n",
        "            print(\"No se pudieron cargar los ejemplos. La secci√≥n de ejemplos estar√° vac√≠a.\")\n",
        "            examples_section = gr.Examples(\n",
        "                examples=examples_data,\n",
        "                inputs=[imagen_input, tipo_analisis, idioma],\n",
        "                label=\"üìö Ejemplo de Uso: Rayos X de T√≥rax (No disponible)\"\n",
        "            )\n",
        "            return examples_section # Retornar aqu√≠ si falla la descarga\n",
        "\n",
        "    # Si la descarga fue exitosa o la imagen ya exist√≠a, definir los ejemplos con la ruta local\n",
        "    examples_data = [\n",
        "        [example_image_filename, \"Reporte Estructurado\", \"Espa√±ol\"],\n",
        "    ]\n",
        "\n",
        "    examples_section = gr.Examples(\n",
        "        examples=examples_data,\n",
        "        inputs=[imagen_input, tipo_analisis, idioma],\n",
        "        label=\"üìö Ejemplo de Uso: Rayos X de T√≥rax\"\n",
        "    )\n",
        "    return examples_section\n",
        "\n",
        "def create_footer():\n",
        "    \"\"\"\n",
        "    Crea y configura el markdown del pie de p√°gina.\n",
        "\n",
        "    Esta secci√≥n contiene informaci√≥n de contacto, enlace al repositorio y\n",
        "    detalles del proyecto.\n",
        "\n",
        "    Returns:\n",
        "        gr.Markdown: El componente Gradio Markdown para el pie de p√°gina.\n",
        "    \"\"\"\n",
        "    footer_markdown = \"\"\"\n",
        "    ---\n",
        "    ### üìû Informaci√≥n del Proyecto\n",
        "\n",
        "    **Contacto:** ymoral35@estudiante.ibero.edu.co\n",
        "    **Repositorio:** [Documentaci√≥n completa disponible pr√≥ximamente]\n",
        "    **Versi√≥n:** MVP 1.0 (Octubre 2025)\n",
        "\n",
        "    *Desarrollado como parte del programa de Pr√°ctica Profesional (PICD) en Ingenier√≠a en Ciencia de Datos*\n",
        "    \"\"\"\n",
        "    return gr.Markdown(footer_markdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77e42f94"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import traceback\n",
        "\n",
        "def analizar_imagen(imagen, tipo_analisis=\"Reporte Estructurado\", idioma=\"Espa√±ol\"):\n",
        "    \"\"\"\n",
        "    Analiza una imagen m√©dica utilizando el modelo Med-GEMMA.\n",
        "\n",
        "    Procesa la imagen de entrada junto con un prompt basado en el tipo de an√°lisis y idioma\n",
        "    seleccionados. Genera un reporte m√©dico estructurado o descriptivo.\n",
        "\n",
        "    Args:\n",
        "        imagen (PIL.Image.Image): La imagen m√©dica a analizar.\n",
        "        tipo_analisis (str, optional): El tipo de an√°lisis a realizar.\n",
        "            Puede ser \"Descripci√≥n General\", \"Hallazgos Patol√≥gicos\",\n",
        "            \"Reporte Estructurado\", o \"Diagn√≥stico Diferencial\".\n",
        "            Por defecto es \"Reporte Estructurado\".\n",
        "        idioma (str, optional): El idioma en el que se generar√° el reporte.\n",
        "            Puede ser \"Espa√±ol\" o \"Ingl√©s\". Por defecto es \"Espa√±ol\".\n",
        "\n",
        "    Returns:\n",
        "        tuple: Una tupla conteniendo:\n",
        "            - str: El reporte m√©dico generado o un mensaje de error.\n",
        "            - str: Metadatos del procesamiento (tiempo, modelo, GPU, etc.).\n",
        "            - str: El estado del proceso (Completado, Error).\n",
        "    \"\"\"\n",
        "\n",
        "    # Validar si se ha cargado una imagen\n",
        "    if imagen is None:\n",
        "        return \"‚ùå Por favor carga una imagen primero\", \"\", \"Error: Sin imagen\"\n",
        "\n",
        "    try:\n",
        "        inicio = time.time()\n",
        "\n",
        "        # Prompts en espa√±ol para los diferentes tipos de an√°lisis\n",
        "        prompts = {\n",
        "            \"Descripci√≥n General\": \"Describe esta imagen m√©dica identificando las estructuras anat√≥micas visibles.\",\n",
        "            \"Hallazgos Patol√≥gicos\": \"Identifica cualquier hallazgo patol√≥gico o anormal en esta imagen m√©dica.\",\n",
        "            \"Reporte Estructurado\": \"Genera un reporte m√©dico estructurado con: T√âCNICA, HALLAZGOS e IMPRESI√ìN.\",\n",
        "            \"Diagn√≥stico Diferencial\": \"Proporciona un diagn√≥stico diferencial basado en los hallazgos visibles.\"\n",
        "        }\n",
        "\n",
        "        # Obtener el prompt adecuado seg√∫n el tipo de an√°lisis, con fallback a \"Reporte Estructurado\"\n",
        "        prompt = prompts.get(tipo_analisis, prompts[\"Reporte Estructurado\"])\n",
        "\n",
        "        # Preparar los mensajes en el formato de chat para el modelo\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": [{\"type\": \"text\", \"text\": \"Eres un radi√≥logo experto especializado en interpretaci√≥n de im√°genes m√©dicas.\"}]\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\"type\": \"image\", \"image\": imagen}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Aplicar el template de chat y tokenizar la entrada\n",
        "        # Primero aplicar template sin tokenizar para obtener el texto completo\n",
        "        text_inputs = processor.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=False  # Importante: primero sin tokenizar\n",
        "        )\n",
        "\n",
        "        # Luego tokenizar por separado incluyendo la imagen\n",
        "        inputs = processor(\n",
        "            text=text_inputs,\n",
        "            images=imagen,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        # Mover los tensores de entrada al dispositivo de procesamiento (GPU o CPU)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Obtener la longitud de los tokens de entrada para decodificar solo la respuesta\n",
        "        input_len = inputs[\"input_ids\"].shape[-1]\n",
        "\n",
        "        # Generar la respuesta del modelo\n",
        "        print(f\"ü§ñ Generando reporte...\")\n",
        "\n",
        "        # Usar torch.no_grad() para deshabilitar el c√°lculo de gradientes durante la inferencia\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=350,  # N√∫mero m√°ximo de tokens a generar\n",
        "                do_sample=False,  # Deshabilitar muestreo para una salida determin√≠stica\n",
        "                num_beams=1, # Usar beam search con 1 haz (equivalente a greedy search)\n",
        "                pad_token_id=processor.tokenizer.pad_token_id, # ID del token de padding\n",
        "                eos_token_id=processor.tokenizer.eos_token_id # ID del token de fin de secuencia\n",
        "            )\n",
        "\n",
        "        # Decodificar solo los tokens generados por el modelo (excluyendo los tokens de entrada)\n",
        "        generated_tokens = outputs[0][input_len:]\n",
        "        reporte = processor.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "        tiempo = time.time() - inicio\n",
        "\n",
        "        # Agregar un disclaimer m√©dico al reporte\n",
        "        disclaimer = \"\"\"\n",
        "\n",
        "‚ö†Ô∏è DISCLAIMER M√âDICO:\n",
        "Este reporte es generado por IA con prop√≥sito educativo y demostrativo √∫nicamente.\n",
        "NO debe utilizarse para decisiones cl√≠nicas sin validaci√≥n por profesionales m√©dicos.\n",
        "Proyecto acad√©mico - Corporaci√≥n Universitaria Iberoamericana.\n",
        "\"\"\"\n",
        "\n",
        "        reporte_final = reporte + disclaimer\n",
        "\n",
        "        # Generar metadatos del procesamiento\n",
        "        metadata = f\"\"\"\n",
        "üìä **Informaci√≥n de Procesamiento:**\n",
        "- ‚è±Ô∏è Tiempo: {tiempo:.2f} segundos\n",
        "- ü§ñ Modelo: Med-GEMMA 4B (Google Health AI)\n",
        "- üíª GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\n",
        "- üìù Tokens generados: {len(generated_tokens)}\n",
        "- üîß Tipo an√°lisis: {tipo_analisis}\n",
        "\"\"\"\n",
        "\n",
        "        # Establecer el estado de completado\n",
        "        status = f\"‚úÖ Completado exitosamente en {tiempo:.2f}s\"\n",
        "\n",
        "        return reporte_final, metadata, status\n",
        "\n",
        "    except Exception as e:\n",
        "        # Capturar y formatear cualquier error que ocurra durante el procesamiento\n",
        "        error_msg = f\"\"\"\n",
        "‚ùå ERROR durante el an√°lisis:\n",
        "\n",
        "{str(e)}\n",
        "\n",
        "**Posibles soluciones:**\n",
        "1. Verifica que tengas GPU habilitada (Runtime > Change runtime type)\n",
        "2. Reinicia el runtime (Runtime > Restart runtime)\n",
        "3. Intenta con una imagen m√°s peque√±a\n",
        "4. Si persiste, puede ser l√≠mite de memoria - prueba cerrar otras pesta√±as\n",
        "\"\"\"\n",
        "        print(f\"\\n‚ùå Error completo:\\n{traceback.format_exc()}\")\n",
        "        # Retornar mensajes de error y estado\n",
        "        return error_msg, \"Error en procesamiento\", \"‚ùå Error\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9effbec7"
      },
      "outputs": [],
      "source": [
        "# Definir el CSS para la interfaz de Gradio.\n",
        "css = \"\"\"\n",
        ".gradio-container {\n",
        "    max-width: 1400px !important;\n",
        "    margin: auto;\n",
        "}\n",
        "h1 {\n",
        "    text-align: center;\n",
        "    color: #2563eb;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Iniciar un contexto gr.Blocks para construir la interfaz.\n",
        "with gr.Blocks(title=\"MedFlow MVP\", theme=gr.themes.Soft(), css=css) as demo:\n",
        "\n",
        "    # Agregar el t√≠tulo principal y la descripci√≥n en formato Markdown.\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üè• MedFlow - Producto M√≠nimo Viable\n",
        "    ## Sistema de Interpretaci√≥n Automatizada de Im√°genes M√©dicas\n",
        "\n",
        "    **Proyecto de Pr√°ctica Profesional - Ingenier√≠a en Ciencia de Datos**\n",
        "    **Desarrollado por:** Yeinmy Daniela Morales Barrera\n",
        "    **Instituci√≥n:** Corporaci√≥n Universitaria Iberoamericana\n",
        "    **Modelo:** Med-GEMMA 4B (Google Health AI)\n",
        "\n",
        "    ---\n",
        "    \"\"\")\n",
        "\n",
        "    # Crear un layout horizontal para las secciones de entrada y salida.\n",
        "    with gr.Row():\n",
        "        # Agregar la columna de entrada y capturar los componentes retornados.\n",
        "        input_col, imagen_input, tipo_analisis, idioma, procesar_btn, limpiar_btn = create_input_section()\n",
        "\n",
        "        # Agregar la columna de salida y capturar los componentes retornados.\n",
        "        output_col, reporte_output, status_output = create_output_section()\n",
        "\n",
        "    # Agregar la secci√≥n de metadatos (acorde√≥n).\n",
        "    metadata_acc, metadata_output = create_metadata_accordion()\n",
        "\n",
        "    # Agregar la secci√≥n de gu√≠a de uso (acorde√≥n).\n",
        "    guide_acc = create_guide_accordion()\n",
        "\n",
        "    # Agregar la secci√≥n de ejemplos.\n",
        "    examples_section = create_examples_section(imagen_input, tipo_analisis, idioma)\n",
        "\n",
        "    # Agregar el pie de p√°gina.\n",
        "    footer = create_footer()\n",
        "\n",
        "    # Conectar el evento click del bot√≥n de procesar con la funci√≥n analizar_imagen.\n",
        "    procesar_btn.click(\n",
        "        fn=analizar_imagen,\n",
        "        inputs=[imagen_input, tipo_analisis, idioma],\n",
        "        outputs=[reporte_output, metadata_output, status_output]\n",
        "    )\n",
        "\n",
        "# Agregar las declaraciones print para lanzar la aplicaci√≥n.\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üöÄ LANZANDO MEDFLOW MVP\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n‚úÖ Todo configurado correctamente\")\n",
        "print(\"üì± La interfaz se abrir√° autom√°ticamente\")\n",
        "print(\"üîó Compartir√°s un link p√∫blico temporal (v√°lido 72h)\")\n",
        "print(\"\\n‚ö†Ô∏è IMPORTANTE: No cierres esta pesta√±a mientras uses la app\\n\")\n",
        "\n",
        "# Lanzar la demo de Gradio.\n",
        "demo.launch(\n",
        "    share=True,  # Habilitar enlace p√∫blico compartido\n",
        "    debug=True,  # Habilitar modo debug para ver errores detallados\n",
        "    show_error=True, # Mostrar errores en la UI\n",
        "    server_name=\"0.0.0.0\", # Escuchar en todas las interfaces de red\n",
        "    server_port=7860 # Usar el puerto 7860\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNEpryXtNWoziov3VdRr2fU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}